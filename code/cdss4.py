# -*- coding: utf-8 -*-
"""cdss4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14IMm4J2DP_COGy6vnfHpu1jqn4ARE7tR
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Clone the repository containing the dataset
git clone https://github.com/imharshitaa/Clinical-Decision-Support-System-Healthcare-EPICS-project.git

# Assuming the dataset file is in CSV format, you can use pandas to load it
medicines = pd.read_csv("Clinical-Decision-Support-System-Healthcare-EPICS-project/data/medicine.csv")

# Drop the 'Index' column
medicines.drop(columns=['index'], inplace=True)

# Replace NaN values with 0
medicines.fillna(0, inplace=True)

# Now you can work with the modified dataset
print(medicines.head())

medicines.head()

medicines.shape

medicines.isnull().sum()

medicines.dropna(inplace=True)

medicines.duplicated().sum()

medicines['Description']

medicines['Description'].apply(lambda x:x.split())

medicines['Reason'] = medicines['Reason'].apply(lambda x:x.split())
medicines['Description'] = medicines['Description'].apply(lambda x:x.split())

medicines['Description'] = medicines['Description'].apply(lambda x:[i.replace(" ","") for i in x])

medicines['Description'] = medicines['Description'].apply(lambda x:[i.replace(" ","") for i in x])

medicines['tags'] = medicines['Description'] + medicines['Reason']

# Print column names
print(medicines.columns)

new_df = medicines[['Drug_Name','Reason','tags']]
new_df

new_df['tags'].apply(lambda x:" ".join(x))
new_df

new_df['tags'] = new_df['tags'].apply(lambda x:" ".join(x))
new_df

new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())
new_df

!pip install nltk

import nltk
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

!pip install -U scikit-learn scipy matplotlib

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(stop_words='english',max_features=5000)
def stem(text):
  y = []

  for i in text.split():
    y.append(ps.stem(i))

  return " ".join(y)

new_df['tags'] = new_df['tags'].apply(stem)

cv.fit_transform(new_df['tags']).toarray().shape
vectors = cv.fit_transform(new_df['tags']).toarray()
feature_names = cv.get_feature_names_out()

# Now you can access the feature names
print(feature_names)

from sklearn.metrics.pairwise import cosine_similarity
cosine_similarity(vectors)
similarity = cosine_similarity(vectors)
similarity[1]

def recommend(medicine):
    medicine_index = new_df[new_df['Drug_Name'] == medicine].index[0]
    distances = similarity[medicine_index]
    medicines_list = sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]

    for i in medicines_list:
        print(new_df.iloc[i[0]].Drug_Name)

recommend("Paracetamol 125mg Syrup 60mlParacetamol 500mg Tablet 10'S")
import pickle
pickle.dump(new_df.to_dict(),open('medicine_dict.pkl','wb'))
pickle.dump(similarity,open('similarity.pkl','wb'))
